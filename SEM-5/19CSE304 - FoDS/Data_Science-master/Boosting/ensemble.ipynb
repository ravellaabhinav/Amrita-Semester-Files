{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ensemble.ipynb","provenance":[],"authorship_tag":"ABX9TyMaoK48rrOouSFkIEIl0yNC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LDt4NDTI65LN","colab_type":"text"},"source":["https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/"]},{"cell_type":"markdown","metadata":{"id":"mRv9lbKc7SQa","colab_type":"text"},"source":["# Combine Model Predictions Into Ensemble Predictions"]},{"cell_type":"markdown","metadata":{"id":"fM-RymfD7TiQ","colab_type":"text"},"source":["The three most popular methods for combining the predictions from different models are:\n","\n","Bagging. Building multiple models (typically of the same type) from different subsamples of the training dataset.\n","\n","Boosting. Building multiple models (typically of the same type) each of which learns to fix the prediction errors of a prior model in the chain.\n","\n","Voting. Building multiple models (typically of differing types) and simple statistics (like calculating the mean) are used to combine predictions."]},{"cell_type":"markdown","metadata":{"id":"L8Xm2RHQ7YRa","colab_type":"text"},"source":["# Bagging Algorithms"]},{"cell_type":"markdown","metadata":{"id":"TLzU9W1C7cWs","colab_type":"text"},"source":["Bootstrap Aggregation or bagging involves taking multiple samples from your training dataset (with replacement) and training a model for each sample.\n","\n","The final output prediction is averaged across the predictions of all of the sub-models.\n","\n","The three bagging models covered in this section are as follows:\n","\n","\n","*   Bagged Decision Trees\n","*   Random Forest\n","*   Extra Trees"]},{"cell_type":"markdown","metadata":{"id":"oitlknl-7nxe","colab_type":"text"},"source":["## 1. Bagged Decision Trees"]},{"cell_type":"code","metadata":{"id":"DHaHNaSf66Dd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"dea4c6a7-8426-482a-8fc6-29bbe58817c2","executionInfo":{"status":"ok","timestamp":1588566372705,"user_tz":-330,"elapsed":6238,"user":{"displayName":"dhanya hari","photoUrl":"","userId":"01887745784407435863"}}},"source":["# Bagged Decision Trees for Classification\n","import pandas\n","from sklearn import model_selection\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = pandas.read_csv(url, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","cart = DecisionTreeClassifier()\n","num_trees = 100\n","model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n","results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["0.770745044429255\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d7vponzf9WHc","colab_type":"text"},"source":["## 2. Random Forest"]},{"cell_type":"code","metadata":{"id":"3w50Zi1C9W2c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"3e38ff17-37ad-4b3b-8e31-cdc385354983","executionInfo":{"status":"ok","timestamp":1588566794142,"user_tz":-330,"elapsed":3316,"user":{"displayName":"dhanya hari","photoUrl":"","userId":"01887745784407435863"}}},"source":["# Random Forest Classification\n","import pandas\n","from sklearn import model_selection\n","from sklearn.ensemble import RandomForestClassifier\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = pandas.read_csv(url, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","num_trees = 100\n","max_features = 3\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n","results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["0.770745044429255\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RofYAM9A9eez","colab_type":"text"},"source":["## 3. Extra Trees"]},{"cell_type":"code","metadata":{"id":"Uiyrr1J79ZJs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"c4325d50-03a7-46bc-bfc7-12370b80388e","executionInfo":{"status":"ok","timestamp":1588566829307,"user_tz":-330,"elapsed":3022,"user":{"displayName":"dhanya hari","photoUrl":"","userId":"01887745784407435863"}}},"source":["# Extra Trees Classification\n","import pandas\n","from sklearn import model_selection\n","from sklearn.ensemble import ExtraTreesClassifier\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = pandas.read_csv(url, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","num_trees = 100\n","max_features = 7\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n","results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["0.7551777170198224\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5zwcjqbv9mKN","colab_type":"text"},"source":["# Boosting Algorithms"]},{"cell_type":"markdown","metadata":{"id":"sny4WZ0V9ndN","colab_type":"text"},"source":["Boosting ensemble algorithms creates a sequence of models that attempt to correct the mistakes of the models before them in the sequence.\n","\n","Once created, the models make predictions which may be weighted by their demonstrated accuracy and the results are combined to create a final output prediction.\n","\n","The two most common boosting ensemble machine learning algorithms are:\n","\n","\n","\n","*   AdaBoost\n","*   Stochastic Gradient Boosting"]},{"cell_type":"markdown","metadata":{"id":"NHiRI5sV9ug0","colab_type":"text"},"source":["## 1. AdaBoost"]},{"cell_type":"code","metadata":{"id":"V9VY2Ka19hzz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"6ddb53a9-926b-44d3-9ffe-c169a23ecff0","executionInfo":{"status":"ok","timestamp":1588566899817,"user_tz":-330,"elapsed":3403,"user":{"displayName":"dhanya hari","photoUrl":"","userId":"01887745784407435863"}}},"source":["# AdaBoost Classification\n","import pandas\n","from sklearn import model_selection\n","from sklearn.ensemble import AdaBoostClassifier\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = pandas.read_csv(url, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","num_trees = 30\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n","results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["0.760457963089542\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lXRYC78L92Mm","colab_type":"text"},"source":["## 2. Stochastic Gradient Boosting"]},{"cell_type":"code","metadata":{"id":"978KnfNC9y1c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"ddbe9929-d7ec-477f-a3a2-79df44337d5f","executionInfo":{"status":"ok","timestamp":1588566937320,"user_tz":-330,"elapsed":4008,"user":{"displayName":"dhanya hari","photoUrl":"","userId":"01887745784407435863"}}},"source":["# Stochastic Gradient Boosting Classification\n","import pandas\n","from sklearn import model_selection\n","from sklearn.ensemble import GradientBoostingClassifier\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = pandas.read_csv(url, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","num_trees = 100\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n","results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n","print(results.mean())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"stream","text":["0.7681989063568012\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vLgYA9EJ-BFg","colab_type":"text"},"source":["# Voting Ensemble"]},{"cell_type":"code","metadata":{"id":"91tGjIgi7u0c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a7ac364e-142a-4b6d-e315-3bb28840fc11","executionInfo":{"status":"ok","timestamp":1588566981122,"user_tz":-330,"elapsed":2364,"user":{"displayName":"dhanya hari","photoUrl":"","userId":"01887745784407435863"}}},"source":["# Voting Ensemble for Classification\n","import pandas\n","from sklearn import model_selection\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = pandas.read_csv(url, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","seed = 7\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","# create the sub models\n","estimators = []\n","model1 = LogisticRegression()\n","estimators.append(('logistic', model1))\n","model2 = DecisionTreeClassifier()\n","estimators.append(('cart', model2))\n","model3 = SVC()\n","estimators.append(('svm', model3))\n","# create the ensemble model\n","ensemble = VotingClassifier(estimators)\n","results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n","print(results.mean())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n","  FutureWarning\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["0.7655673274094328\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]}]}